{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "BASE='http://www.rannnafeirste.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "\tdef __init__(self, id, title):\n",
    "\t\tself.id = id\n",
    "\t\tself.title = title\n",
    "\t\tself.url = '{}/{}'.format(BASE, id)\n",
    "\n",
    "\t# TODO: stop trying to make fetch happen\n",
    "\tdef _fetch_text(self):\n",
    "\t\treq = requests.get(self.url)\n",
    "\t\tif req.status_code != 200:\n",
    "\t\t\traise Exception('Error fetching page ' + self.url)\n",
    "\t\tself.content = req.content\n",
    "\tdef _soupynorman(self):\n",
    "\t\tself.soup = BeautifulSoup(self.content, 'html.parser')\n",
    "\tdef _fetch_audio(self):\n",
    "\t\taudio_div = self.soup.find(\"div\", class_='sqs-audio-embed')\n",
    "\t\tself.audio = audio_div[\"data-url\"]\n",
    "\tdef _fetch_fragments(self):\n",
    "\t\tfor i in self.soup.find_all(\"div\", class_='sqs-block-content'):\n",
    "\t\t\tchildren = list(i.children)\n",
    "\t\t\tif children[0].name == \"h1\":\n",
    "\t\t\t\tself.fragments = children\n",
    "\t## don't actually need this, because the title comes from the landing page\n",
    "\tdef _fetch_title(self):\n",
    "\t\tif self.fragments[0].name == \"h1\":\n",
    "\t\t\tself.title = fragments[0].text\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Error reading title: ' + self.url)\n",
    "\tdef _fetch_author(self):\n",
    "\t\tif len(self.fragments) > 2 and self.fragments[1].name == \"h2\":\n",
    "\t\t\tself.author = self.fragments[1].text\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Error reading author: ' + self.url)\n",
    "\tdef _fetch_paragraphs(self):\n",
    "\t\traw_paras = [n for n in self.fragments if n.name == \"p\"]\n",
    "\t\tfor frag in raw_paras:\n",
    "\t\t\tfor br in frag.find_all(\"br\"):\n",
    "\t\t\t\tbr.insert(0, '\\n')\n",
    "\t\t\t\tbr.unwrap()\n",
    "\t\tfirst = list(raw_paras[0].children)\n",
    "\t\tif len(first) == 1 and first[0].name == 'em':\n",
    "\t\t\t\tself.em_para = raw_paras[0].text.strip()\n",
    "\t\t\t\tdel raw_paras[0]\n",
    "\t\textent = len(raw_paras)\n",
    "\t\tcounter = 0\n",
    "\t\tfor i in raw_paras:\n",
    "\t\t\t\tif i.text.strip().startswith('Nóta') or i.text.strip().startswith('NÓTA') and extent > counter:\n",
    "\t\t\t\t\textent = counter\n",
    "\t\t\t\tcounter += 1\n",
    "\t\tfilt = raw_paras[0:extent]\n",
    "\t\tself.paragraphs = [p.text for p in filt]\n",
    "\tdef get_initials(self):\n",
    "\t\tfada = {\n",
    "\t\t\t'Á': 'A',\n",
    "\t\t\t'É': 'E',\n",
    "\t\t\t'Í': 'I',\n",
    "\t\t\t'Ó': 'O',\n",
    "\t\t\t'Ú': 'U'\n",
    "\t\t}\n",
    "\t\tdef initial(s):\n",
    "\t\t\tif s == None or len(s) < 1:\n",
    "\t\t\t\treturn ''\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn fada.get(s.upper()[0]) or s.upper()[0]\n",
    "\t\ttry:\n",
    "\t\t\treturn \"\".join([initial(i) for i in self.author.split(' ')])\n",
    "\t\texcept:\n",
    "\t\t\tprint('Author missing: did you run scrape()?')\n",
    "\n",
    "\tdef _specifics(self):\n",
    "\t\ttitle = ['mo-bhaile-dchais', 'taiscidh-ghleann-domhain', 'banron-an-uaignis', 'non-an-r-agus-an-frog', 'seanchaithe-agus-fil-rann-na-feirste', 'an-ghaeltacht-bheo']\n",
    "\t\ttitlele = ['liontar-duinn-an-cruiscin', 'oireachtas-na-ndise', 'fidilir-ghleann-fhinne']\n",
    "\n",
    "\t\tif self.id in title:\n",
    "\t\t\tself.paragraphs.insert(0, self.title)\n",
    "\n",
    "\t\tif self.id in titlele:\n",
    "\t\t\tsecond = self.em_para.replace(' a chum', '')\n",
    "\t\t\tself.paragraphs.insert(0, '{} le {}'.format(self.title, second))\n",
    "\n",
    "\tdef scrape(self):\n",
    "\t\tself._fetch_text()\n",
    "\t\tself._soupynorman()\n",
    "\t\tself._fetch_audio()\n",
    "\t\tself._fetch_fragments()\n",
    "\t\tself._fetch_author()\n",
    "\t\tself._fetch_paragraphs()\n",
    "\t\tself._specifics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing = requests.get('http://www.rannnafeirste.com/reamhra')\n",
    "lsoup = BeautifulSoup(landing.content, 'html.parser')\n",
    "main_nav = lsoup.find(\"nav\", id='mainNavigation')\n",
    "inner_nav=main_nav.find(\"div\", class_='folder active')\n",
    "stories = inner_nav.find_all('div', class_='collection')\n",
    "links = [ i.find('a') for i in stories ]\n",
    "if links[0].attrs['href'] == '/reamhra':\n",
    "\tlinks = links[1:]\n",
    "def extract_link(a):\n",
    "\tout = dict()\n",
    "\tout['id'] = a.attrs['href'][1:]\n",
    "\tout['page'] = BASE + a.attrs['href']\n",
    "\tout['title'] = a.text.strip()\n",
    "\treturn out\n",
    "olinks = list(map(extract_link, links))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
