{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from [PyTorch Speaker Verification](https://github.com/HarryVolek/PyTorch_Speaker_Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.8.0)\n",
      "Collecting webrtcvad\n",
      "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 4.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.49.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.23.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (46.1.3.post20200325)\n",
      "Requirement already satisfied: llvmlite<=0.33.0.dev0,>=0.31.0.dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.23.0)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (20.1)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
      "Building wheels for collected packages: webrtcvad\n",
      "  Building wheel for webrtcvad (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=93074 sha256=15b3836cfd63bc6b82a3fbf05e86f9960f25fbebfe854e5119e8bd24b0db5aec\n",
      "  Stored in directory: /workspace/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
      "Successfully built webrtcvad\n",
      "Installing collected packages: webrtcvad\n",
      "Successfully installed webrtcvad-2.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa webrtcvad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BSD 3-Clause License\n",
    "\n",
    "Copyright (c) 2019, HarryVolek\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation\n",
    "  and/or other materials provided with the distribution.\n",
    "\n",
    "* Neither the name of the copyright holder nor the names of its\n",
    "  contributors may be used to endorse or promote products derived from\n",
    "  this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Dec 18 16:22:41 2018\n",
    "\n",
    "@author: Harry\n",
    "Modified from https://github.com/wiseman/py-webrtcvad/blob/master/example.py\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import librosa\n",
    "import wave\n",
    "\n",
    "import webrtcvad\n",
    "\n",
    "#from hparam import hparam as hp\n",
    "sr = 16000\n",
    "\n",
    "def read_wave(path, sr):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    Assumes sample width == 2\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "    data, _ = librosa.load(path, sr)\n",
    "    assert len(data.shape) == 1\n",
    "    assert sr in (8000, 16000, 32000, 48000)\n",
    "    return data, pcm_data\n",
    "    \n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                start = ring_buffer[0][0].timestamp\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = False\n",
    "                yield (start, frame.timestamp + frame.duration)\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield (start, frame.timestamp + frame.duration)\n",
    "\n",
    "\n",
    "def VAD_chunk(aggressiveness, path):\n",
    "    audio, byte_audio = read_wave(path, sr)\n",
    "    vad = webrtcvad.Vad(int(aggressiveness))\n",
    "    frames = frame_generator(20, byte_audio, sr)\n",
    "    frames = list(frames)\n",
    "    times = vad_collector(sr, 20, 200, vad, frames)\n",
    "    speech_times = []\n",
    "    speech_segs = []\n",
    "    for i, time in enumerate(times):\n",
    "        start = np.round(time[0],decimals=2)\n",
    "        end = np.round(time[1],decimals=2)\n",
    "        j = start\n",
    "        while j + .4 < end:\n",
    "            end_j = np.round(j+.4,decimals=2)\n",
    "            speech_times.append((j, end_j))\n",
    "            speech_segs.append(audio[int(j*sr):int(end_j*sr)])\n",
    "            j = end_j\n",
    "        else:\n",
    "            speech_times.append((j, end))\n",
    "            speech_segs.append(audio[int(j*sr):int(end*sr)])\n",
    "    return speech_times, speech_segs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
